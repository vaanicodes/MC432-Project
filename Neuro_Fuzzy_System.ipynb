{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuro Fuzzy System.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzdGB/xDBd9cVbXapm17BM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaanicodes/MC432-Project/blob/main/Neuro_Fuzzy_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dynamic Clustering"
      ],
      "metadata": {
        "id": "D5jT6xWf1S0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ciz95uW0e-4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def clustering(df,count):\n",
        "    df.sort_values(by=df.columns[count],inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    Target = list(df['class'])\n",
        "    q = df['class'][0]\n",
        "    Cluster_form = list()\n",
        "    cl = list()\n",
        "    for i in range(0,len(Target)):\n",
        "        if Target[i] == q:\n",
        "            cl.append(df[df.columns[count]][i])\n",
        "        else:\n",
        "            q = df['class'][i]\n",
        "            Cluster_form.append(cl)\n",
        "            cl = list()\n",
        "            cl.append(df[df.columns[count]][i])\n",
        "    Cluster_form.append(cl)\n",
        "#clustering of feature values\n",
        "    #print(\"CLuster\",z)\n",
        "    s1 = 0\n",
        "    for v in Cluster_form: \n",
        "        s1+=len(v)\n",
        "    Threshhold = s1/len(Cluster_form) \n",
        "    #print(\"s1\",s1)\n",
        "    #print(len(z))\n",
        "    #print(\"t\",Threshhold)\n",
        "    return centroid(Cluster_form,Threshhold)\n",
        "\n",
        "\n",
        "def centroid(Cluster_form,Threshhold):\n",
        "# list as a input for centroid function\n",
        "    def cen(i):\n",
        "        for i in Cluster_form:\n",
        "            ci = sum(i)/len(i)\n",
        "            return ci\n",
        "    \n",
        "    #print(\"len\",len(z))\n",
        "\n",
        "#cluster are combine with other cluster based on less distance between centroid of clusters\n",
        "    for i in Cluster_form:\n",
        "        if len(i) < Threshhold:\n",
        "            if Cluster_form.index(i) == 0:\n",
        "                for t in i:\n",
        "                    Cluster_form[Cluster_form.index(i)+1].append(t)\n",
        "            elif Cluster_form.index(i) == len(Cluster_form)-1:\n",
        "                for t in i:\n",
        "                    Cluster_form[Cluster_form.index(i)-1].append(t)\n",
        "            elif (cen(i)-cen(Cluster_form[Cluster_form.index(i)-1]))<(cen(i)-cen(Cluster_form[Cluster_form.index(i)+1])): \n",
        "                for t in i:\n",
        "                    Cluster_form[Cluster_form.index(i)-1].append(t)     \n",
        "            elif (cen(i)-cen(Cluster_form[Cluster_form.index(i)-1]))>(cen(i)-cen(Cluster_form[Cluster_form.index(i)+1])):\n",
        "                for t in i:\n",
        "                    Cluster_form[Cluster_form.index(i)+1].append(t)\n",
        "\n",
        "#clusters which have member in cluster less than Fth are eliminated\n",
        "    new = list()\n",
        "    for i in Cluster_form:\n",
        "        if len(i) > Threshhold:\n",
        "            new.append(i)\n",
        "    #print(\"new\",len(new))\n",
        "    #print(\"newnn\",new) #list with newly formed cluster after elimination\n",
        "\n",
        "#mean is calculated\n",
        "    mean = list()\n",
        "    for i in new:\n",
        "        mean.append(sum(i)/len(i))  \n",
        "    #print(mean)\n",
        "    #print('\\n')\n",
        "\n",
        "#sd is calculated\n",
        "    SD = list()\n",
        "    for i in new:\n",
        "        SD.append(np.std(i)) \n",
        "    #print(SD)\n",
        "    return mean,SD\n",
        "\n",
        "\n",
        "def Dynamic_clustering(df):       \n",
        "    count=0   \n",
        "    MEAN=[]\n",
        "    Std_deviation=[]\n",
        "    while count<len(df.columns)-1:\n",
        "        a,b=clustering(df,count)\n",
        "        MEAN.append(a)\n",
        "        Std_deviation.append(b)\n",
        "    \n",
        "    #print(len(df.columns))\n",
        "        count+=1\n",
        "    #print(MEAN)\n",
        "    #print(len(MEAN))\n",
        "    #print(Std_deviation)\n",
        "    return MEAN,Std_deviation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fuzzification"
      ],
      "metadata": {
        "id": "kKK4FtlM1fWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Fuzzification:\n",
        "    def __init__(self, row, mean, sd):\n",
        "        self.row = row #each row with multiple features\n",
        "        self.mean = mean #means from dynamic clustering for each features\n",
        "        self.sd = sd #sds from dynamic clustering for each features\n",
        "        \n",
        "    def normal_density(self, x, mean, sd):\n",
        "        if sd == 0:\n",
        "            if mean == x:\n",
        "                return 1\n",
        "            else:\n",
        "                return 0\n",
        "        return (1/(sd*(2*np.pi))**(0.5))* np.exp(-0.5*((x-mean)/sd)**(2))\n",
        "    \n",
        "    def fuzzify(self):\n",
        "        if len(self.row) != len(self.mean):\n",
        "            raise Exception('Need means for each feature')\n",
        "        if len(self.row) != len(self.sd):\n",
        "            raise Exception('Need sd for each feature')\n",
        "        fuzzy_output = []    \n",
        "        for i in range(len(self.row)):           \n",
        "            clusters = len(self.mean[i])\n",
        "            output = np.zeros((clusters))\n",
        "            densities = []\n",
        "            for j in range(clusters):\n",
        "                density = self.normal_density(self.row[i], self.mean[i][j], self.sd[i][j])\n",
        "                densities.append(density)\n",
        "        \n",
        "            index = densities.index(max(densities))\n",
        "            output[index] = 1\n",
        "            output = output.tolist()\n",
        "            output = [int(x) for x in output]\n",
        "            fuzzy_output.append(output)\n",
        "            #fuzzy_output.append()\n",
        "        return fuzzy_output"
      ],
      "metadata": {
        "id": "umX4_mGO0qlM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Weights Function"
      ],
      "metadata": {
        "id": "sBjtAj2l1mUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "#plt.close(\"all\")\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "# Forecasting Algorith Developed from the Neuro - Fuzzy System\n",
        "# Authors: Phichit Napook and Narissara Eiamkanitcaht\n",
        "#       Chiang Mai University,Thailand\n",
        "# Copyright 2015 Â© 2015 ACM 978-1-4503-3575-1/15/09 $15.00.\n",
        "# http://dx.doi.org/10.1145/2800835.2800983\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Testing Comment for Compilation\n",
        "#print('Starting')\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "#    Neural Network\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "\n",
        "weights  = np.random.rand(2,3)\n",
        "inputs = [[3,3,3],[-3,-3,-3],[4,4,-4]]\n",
        "biases = np.random.rand(2)\n",
        "expectedOutput = [1,0,1]\n",
        "\n",
        "def my_neuron(weightList, inputList, bias, my_function):\n",
        "\tdotproduct = np.dot(weightList,inputList)\n",
        "\tfullproduct = dotproduct + bias\n",
        "\treturn my_function(fullproduct)\n",
        "\n",
        "def my_sigmoid(value):\n",
        "\tvalue2 = value * -1\n",
        "\tsigmoid = 1 / (1 + np.exp(value2))\n",
        "\treturn sigmoid\n",
        "\n",
        "def my_derivative_sigmoid(value):\n",
        "\tsigmoid = my_sigmoid(value) * (1 - my_sigmoid(value))\n",
        "\treturn sigmoid\n",
        "\n",
        "def sigmoid_neuron(weightList, inputList, bias):\n",
        "\treturn my_neuron(weightList, inputList, bias, my_sigmoid)\n",
        "\n",
        "def singleInput_neuron_layer(EveryNeurons_weightList, inputList, EveryNeurons_bias, Individual_neuron):\n",
        "\tfull_output = []\n",
        "\tfor weightList,bias in zip(EveryNeurons_weightList, EveryNeurons_bias):\n",
        "\t\tsingle_output = Individual_neuron(weightList, inputList, bias)\n",
        "\t\tfull_output.append(single_output)\n",
        "\treturn full_output\n",
        "\n",
        "def neuron_layer(EveryNeurons_weightList, Every_inputList, EveryNeurons_bias, Individual_neuron):\n",
        "\tfull_output = []\n",
        "\tfor inputList in Every_inputList:\n",
        "\t\tsingle_output = singleInput_neuron_layer(EveryNeurons_weightList, inputList, EveryNeurons_bias, Individual_neuron)\n",
        "\t\tfull_output.append(single_output)\n",
        "\treturn full_output\n",
        "\n",
        "def simple_error(expectedValue, actualValue):\n",
        "\tdiff = (expectedValue - actualValue) * (expectedValue - actualValue)\n",
        "\treturn diff\n",
        "\n",
        "def layer1_derivative_chain(weightList, expectedValue, actualValue, Adenduminputs, maybeBias):\n",
        "\tdotproduct = np.dot(weightList,Adenduminputs)\n",
        "\tfullproduct = dotproduct + maybeBias\n",
        "\tfull_output = []\n",
        "\tsigmoid_derivative = my_derivative_sigmoid(fullproduct)\n",
        "\t#for w_weight in weightList:\n",
        "\tfor in_input in Adenduminputs:\n",
        "\t\tper_weight_derivative = -0.5 * sigmoid_derivative * (expectedValue - actualValue) * in_input #in_input #w_weight\n",
        "\t\tfull_output.append(per_weight_derivative)\n",
        "\treturn full_output\n",
        "\n",
        "def layer1_bias_chain(weightList, expectedValue, actualValue, Adenduminputs, maybeBias):\n",
        "\tdotproduct = np.dot(weightList,Adenduminputs)\n",
        "\tfullproduct = dotproduct + maybeBias # simple_error(expectedValue, actualValue)\n",
        "\treturn 0 #my_derivative_sigmoid(fullproduct)\n",
        "\n",
        "def layer1_weight_adjustment(weightList, bias, expectedValue, actualValue, Adenduminputs):\n",
        "\tweight_adjustments = layer1_derivative_chain(weightList, expectedValue, actualValue, Adenduminputs, bias)\n",
        "\tbias_adjustment = layer1_bias_chain(weightList, expectedValue, actualValue, Adenduminputs, bias)\n",
        "\tnew_weightList = np.subtract(weightList, weight_adjustments) #np.add for opposite affect subtract\n",
        "\tnew_bias = bias + bias_adjustment\n",
        "\treturn [new_weightList, new_bias]\n",
        "\n",
        "def training_attempt(weightList, bias, inputs, sigmoid_neuron, expectedValue):\n",
        "\tactualValue = singleInput_neuron_layer(weightList,inputs,bias,sigmoid_neuron)\n",
        "\treturn layer1_weight_adjustment(weightList, bias, expectedValue, actualValue, inputs)\n",
        "\n",
        "def multiple_training_attempts(weightLists, biases, inputLists, sigmoid_neuron, expectedValues):\n",
        "\tnew_weightLists = []\n",
        "\tnew_biasList = []\n",
        "\tactualValues = neuron_layer(weightLists,inputLists,biases,sigmoid_neuron)\n",
        "\tfor weightList,bias in zip(weightLists, biases):\n",
        "\t\tfor inputs, expectedValue, actualValue in zip(inputLists, expectedValues, actualValues):\n",
        "\t\t\tadjustments = layer1_weight_adjustment(weightList, bias, expectedValue, actualValue[0], inputs)\n",
        "\t\t\tweightList = adjustments[0]\n",
        "\t\t\tbias = adjustments[1]\n",
        "\t\tnew_biasList.append(bias)\n",
        "\t\tnew_weightLists.append(weightList)\n",
        "\treturn [new_weightLists, new_biasList]\n",
        "\n",
        "def bulk_training(weightLists, biases, inputLists, sigmoid_neuron, expectedValues):\n",
        "\tfor x in range(30):\n",
        "\t\tlistofnewweightsbiases = multiple_training_attempts(weightLists, biases, inputLists, sigmoid_neuron, expectedValues)\n",
        "\t\tweightLists = listofnewweightsbiases[0]\n",
        "\t\tbiases = listofnewweightsbiases[1]\n",
        "\treturn listofnewweightsbiases\n",
        "\n",
        "def sigmoid_training(weightLists, biases, inputLists, expectedValues):\n",
        "\treturn bulk_training(weightLists, biases, inputLists, sigmoid_neuron, expectedValues)\n",
        "\n",
        "def sigmoid_training_special(inputLists, expectedValues):\n",
        "\tinputlength = len(inputLists[0])\n",
        "\tweightLists = np.random.rand(1,inputlength)\n",
        "\tbiases = [0]\n",
        "\treturn bulk_training(weightLists, biases, inputLists, sigmoid_neuron, expectedValues)\n",
        "\n",
        "def neruotest():\n",
        "\tprint(\"Starting Weights and Answer Estimation\")\n",
        "\tprint([weights, biases])\n",
        "\tprint(neuron_layer(weights,inputs,biases,sigmoid_neuron))\n",
        "\tlistofnewweightsbiases = bulk_training(weights,biases, inputs, sigmoid_neuron, expectedOutput)\n",
        "\tprint(\"Ending Weights and Answer Estimation\")\n",
        "\tprint(listofnewweightsbiases)\n",
        "\tprint(neuron_layer(listofnewweightsbiases[0],inputs,listofnewweightsbiases[1],sigmoid_neuron))\n",
        "\n",
        "#neruotest()\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "#    Quadratic Function\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#training_weights = weights\n",
        "\n",
        "#Based on idea that the paper talks about the length of the weights.\n",
        "#maxlength = len(training_weights[0]) # As in the total number of weights that are in a singular node\n",
        "\n",
        "#x_0 = 0 #Lowest weight is 0 in sigmoid\n",
        "#x_1 = random.randint(1,maxlength)#np.random.choice(training_weights)#np.random.rand(1)[0] #Random weight in sigmoid between 0 and 1\n",
        "#x_2 = maxlength#max(training_weights) #Highest weight is 1 in sigmoid\n",
        "#x_3 = 0 # Not Initialized Yet.\n",
        "\n",
        "# A, if a weight set applied to an input set is equal to 1, else 0\n",
        "\n",
        "def calc_x_uninitialized(x,training_data,training_weights):\n",
        "\tcalc_sum = 0\n",
        "\tfor training_weight in training_weights:\n",
        "\t\t#Big_A = 1\n",
        "\t\tfor training_item in training_data:\n",
        "\t\t\tBig_A = 1\n",
        "\t\t\tj = 0\n",
        "\t\t\twhile ((Big_A == 1) and (j < x) and (j < len(training_weights[0]))) :\n",
        "\t\t\t\tif (training_item[j] * training_weight[j] >= .9):\n",
        "\t\t\t\t\tBig_A = 1\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tBig_A = 0\n",
        "\t\t\t\tj += 1\n",
        "\t\t\tcalc_sum += Big_A\n",
        "\treturn calc_sum\n",
        "\n",
        "def calc_x3_internal(x_0,x_1,x_2, training_data, training_weights):\n",
        "\tdef f(x):\n",
        "\t\treturn calc_x_uninitialized(x,training_data,training_weights)\n",
        "\ttop_half = f(x_2)*((x_0**2)-(x_1**2)) + f(x_0)*((x_1**2)-(x_2**2)) + f(x_1)*((x_2**2)-(x_0**2))\n",
        "\tbottom_half = 2*f(x_2)*(x_0-x_1) +  2*f(x_0)*(x_1-x_2) +  2*f(x_1)*(x_2-x_0)\n",
        "\tif bottom_half == 0:\n",
        "\t\treturn top_half/.1\n",
        "\treturn top_half/bottom_half\n",
        "\n",
        "def calc_x(training_data, training_weights):\n",
        "\tmaxlength = len(training_weights[0])\n",
        "\tx_0 = 1 #Lowest weight is 0 in sigmoid\n",
        "\tx_1 = random.randint(1,maxlength)#np.random.choice(training_weights)#np.random.rand(1)[0] #Random weight in sigmoid between 0 and 1\n",
        "\tx_2 = maxlength#max(training_weights) #Highest weight is 1 in sigmoid\n",
        "\tx_3 = 0\n",
        "\tdef f(x):\n",
        "\t\treturn calc_x_uninitialized(x,training_data,training_weights)\n",
        "\tx_3 = calc_x3_internal(x_0,x_1,x_2, training_data, training_weights)\n",
        "\tf_x_3 = f(x_3)\n",
        "\tf_x_2 = f(x_2)\n",
        "\tf_x_0 = f(x_0)\n",
        "\tf_x_1 = f(x_1)\n",
        "\twhile ((f_x_0- f_x_1) >= 0):\n",
        "\t\t#do all this\n",
        "\t\tif (f_x_3 == f_x_2):\n",
        "\t\t\tx_2 = x_3\n",
        "\t\t\tf_x_2 = f_x_3\n",
        "\n",
        "\t\t#Iterate_random process of X_1 ???\n",
        "\t\telif (f_x_3 < f_x_2):\n",
        "\t\t\tx_0 = x_3\n",
        "\t\t\tf_x_2 = f_x_3\n",
        "\t\tprint(\"I'm here\")\n",
        "\n",
        "\t\tx_1 = x_3\n",
        "\t\tf_x_1 = f_x_3\n",
        "\t\ttop_half = f_x_2*((x_0**2)-(x_1**2)) + f_x_0*((x_1**2)-(x_2**2)) + f_x_1*((x_2**2)-(x_0**2))\n",
        "\t\tbottom_half = 2*f_x_2*(x_0-x_1) +  2*f_x_0*(x_1-x_2) +  2*f_x_1*(x_2-x_0)\n",
        "\t\tif bottom_half == 0:\n",
        "\t\t\tx_3 = top_half/.1\n",
        "\t\telse:\n",
        "\t\t\tx_3 = top_half/bottom_half\n",
        "\t\tf_x_3 = f(x_3)\n",
        "\tprint(f_x_3)\n",
        "\treturn x_1\n",
        "#print(calc_x(x_0,x_1,x_2, inputs, weights))\n",
        "# Use X_1 to creat the binary clasification somehow???\n",
        "\n",
        "\n",
        "def important_feature_selection(listofweights):\n",
        "\tnewlist = listofweights[0]\n",
        "\treturnlist = []\n",
        "\tcount = 0\n",
        "\tfor i in newlist:\n",
        "\t\treturnlist.append((i,count))\n",
        "\t\tcount += 1\n",
        "\tnewerlist = sorted(returnlist, reverse = True)\n",
        "\treturn newerlist\n",
        "\n",
        "def important_feature_selection_last(listofweights):\n",
        "\tnewlist = listofweights[0]\n",
        "\treturnlist = []\n",
        "\tcount = 0\n",
        "\tfor i in newlist:\n",
        "\t\treturnlist.append((i,count))\n",
        "\t\tcount += 1\n",
        "\tnewerlist = sorted(returnlist, reverse = True)\n",
        "\treturn newerlist[-10:]\n",
        "\n",
        "#classifier(x_0,x_1,x_2, new_inputs,  ,trained_weights)\n",
        "weights  = np.random.rand(2,3)\n",
        "inputs = [[3,3,3],[-3,-3,-3],[4,4,-4]]\n",
        "biases = np.random.rand(2)\n",
        "expectedOutput = [1,0,1]\n",
        "\n",
        "def fulltest():\n",
        "\tprint(\"Starting Weights and Answer Estimation\")\n",
        "\tprint([weights, biases])\n",
        "\t#print(neuron_layer(weights,inputs,biases,sigmoid_neuron))\n",
        "\tlistofnewweightsbiases = sigmoid_training_special(inputs, expectedOutput)\n",
        "\tprint(\"Ending Weights and Answer Estimation\")\n",
        "\tprint(listofnewweightsbiases)\n",
        "\t\n",
        "\t#classifier_x = calc_x(inputs, listofnewweightsbiases[0])\n",
        "\tclassifier_x = important_feature_selection(listofnewweightsbiases[0])\n",
        "\tprint(\"Classifier Rule Estimation\")\n",
        "\tprint(classifier_x)\n",
        "\n",
        "\t#somevalue = 3\n",
        "\tdef my_rule(x):\n",
        "\t\tif my_sigmoid(x) > classifier_x:\n",
        "\t\t\treturn 1\n",
        "\t\telse:\n",
        "\t\t\treturn 0\n",
        "\t#print(my_rule(somevalue))\n",
        "\n"
      ],
      "metadata": {
        "id": "kafwOflK0tMg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quadrification"
      ],
      "metadata": {
        "id": "U4l5X3hh1w6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def thefunction(x,sortedlistofweights,fuzzyvalues): # the list of weights have to be sorted\n",
        "    if x > len(sortedlistofweights):\n",
        "        return \"Input not in range!\"\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    sum = 0\n",
        "    for item in fuzzyvalues:\n",
        "        j = 0\n",
        "        while j < x:\n",
        "            if item[sortedlistofweights[j][1]] == 1 and sortedlistofweights[j][0] > 0.98:\n",
        "                A = 1\n",
        "            else:\n",
        "                A = 0\n",
        "            j += 1\n",
        "        sum = sum + A\n",
        "    return sum\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "gr = (math.sqrt(5) - 1) / 2\n",
        "\n",
        "def gss(f, a, b, tol = .01):\n",
        "    c = b - (b - a) * gr\n",
        "    d = a + (b - a) * gr\n",
        "    while abs(b - a) > tol:\n",
        "        if f(c) < f(d):\n",
        "            b = d\n",
        "        else:\n",
        "            a = c\n",
        "\n",
        "        # We recompute both c and d here to avoid loss of precision which may lead to incorrect results or infinite loop\n",
        "        c = b - (b - a) * gr\n",
        "        d = a + (b - a) * gr\n",
        "\n",
        "    return (b + a) / 2\n"
      ],
      "metadata": {
        "id": "9Q85FpUK0wfe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on mesothelioma data"
      ],
      "metadata": {
        "id": "FgSFAduZ15Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "meso_data = pd.read_excel(\"/content/Mesothelioma data set.xlsx\", header = 0)\n",
        "data = meso_data[meso_data.columns[1:len(meso_data.columns)-1]]\n",
        "column_list= list(data.columns)\n",
        "for name in column_list:\n",
        "    data = data.rename(columns={name:\"feat\"+str(column_list.index(name))})\n",
        "\n",
        "#targets classes \n",
        "t=  meso_data[['class of diagnosis']].replace([1,2],[0,1])\n",
        "\n",
        "#this is dataframe with cleaned data which has the features and the class(either 0(M) or 1(B))\n",
        "df = pd.concat([data, t], axis=1)\n",
        "df = df.rename(columns={\"class of diagnosis\":\"class\"})\n",
        "#print(df.sample(n=5))\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)\n",
        "\n",
        "#desired_t = [[1,0],[0,1]]\n",
        "#targets in list format for neural netwrork eg. [0,1] for class being B [1,0] for class being M\n",
        "train_t = [int(x) for x in train.values[:,-1]]\n",
        "\n",
        "test_t = [int(x) for x in test.values[:,-1]]\n",
        "\n",
        "\n",
        "\n",
        "#means and sds from dynamic clustering\n",
        "MEAN,Std_deviation = Dynamic_clustering(train)\n",
        "\n",
        "#values after fuzzification.. it's a list of list.\n",
        "fuzzy_values = []\n",
        "train_f = train.iloc[: , :-1]\n",
        "\n",
        "for index, row in train_f.iterrows():\n",
        "    f = Fuzzification(row, MEAN, Std_deviation)\n",
        "    fuzzy_val = f.fuzzify()\n",
        "    fuzzy_values.append(sum(fuzzy_val, []))\n",
        "    \n",
        "fuzzy_values_test = []\n",
        "test_f = test.iloc[: , :-1]\n",
        "\n",
        "for index, row in test_f.iterrows():\n",
        "    f = Fuzzification(row, MEAN, Std_deviation)\n",
        "    fuzzy_val = f.fuzzify()\n",
        "    fuzzy_values_test .append(sum(fuzzy_val, []))\n",
        "\n",
        "\n",
        "\n",
        "# Training the network to pick out best weights\n",
        "listofnewweightsbiases = sigmoid_training_special(fuzzy_values, train_t)\n",
        "#sorting the weights\n",
        "sortedweights = important_feature_selection(listofnewweightsbiases[0])\n",
        "\n",
        "\n",
        "def g(x):\n",
        "\treturn thefunction(x,sortedweights,fuzzy_values)\n",
        "num = gss(g,0,20)\n",
        "\n",
        "#print(train_t)\n",
        "#print(\"\\n\")\n",
        "#print(fuzzy_values_test)\n",
        "#result = neuron_layer(listofnewweightsbiases[0],fuzzy_values_test,listofnewweightsbiases[1],sigmoid_neuron)\n",
        "#print(result)\n",
        "\n",
        "# Finding the accuracy of our rule creation.\n",
        "\n",
        "def test_nerual_accuracy(listofresults,listofactual):\n",
        "\tcount = 0\n",
        "\tfor result, actual in zip(listofresults, listofactual):\n",
        "\t\tif result[0] == actual:\n",
        "\t\t\tcount += 1\n",
        "\treturn count/len(listofresults)\n",
        "\n",
        "# Result is only for guaging neural network accuracy \n",
        "# MAKE RULES METHOD\n",
        "# [1,0,1,0,1,0....]\n",
        "# n specifies the no: of important feature chosen\n",
        "print(sortedweights[:5])\n",
        "print(fuzzy_values_test[0])\n",
        "def myrules(input,n):\n",
        "\tfor a in sortedweights[:n]:\n",
        "\t\t#print(a[1])\n",
        "\t\tif input[a[1]] == 1:\n",
        "\t\t\treturn 1\n",
        "\treturn 0\n",
        "\n",
        "def applyrules(all_inputs,n):\n",
        "\tmynewlist = []\n",
        "\tfor inputs in all_inputs:\n",
        "\t\tmynewlist.append(myrules(inputs,n))\n",
        "\treturn mynewlist\n",
        "\n",
        "def test_rule_accuracy(listofresults,listofactual):\n",
        "\tcount = 0\n",
        "\tfor result, actual in zip(listofresults, listofactual):\n",
        "\t\tif result == actual:\n",
        "\t\t\tcount += 1\n",
        "\treturn count/len(listofresults)\n",
        "\n",
        "for i in [3,5,8,10,15,int(num)]:\n",
        "\tprint(\"The accuracy of our rules  with top\" , i, \"features is:\", test_rule_accuracy(applyrules(fuzzy_values_test,i), test_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80XPKlZY0zwv",
        "outputId": "7311b0d7-587e-4cad-ed0d-957818626eb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.9999419255923946, 113), (0.9994564216460736, 538), (0.9987715666161301, 948), (0.9982727770990693, 831), (0.9942629105186784, 366)]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The accuracy of our rules  with top 3 features is: 0.8\n",
            "The accuracy of our rules  with top 5 features is: 0.8\n",
            "The accuracy of our rules  with top 8 features is: 0.6461538461538462\n",
            "The accuracy of our rules  with top 10 features is: 0.6461538461538462\n",
            "The accuracy of our rules  with top 15 features is: 0.676923076923077\n",
            "The accuracy of our rules  with top 17 features is: 0.676923076923077\n"
          ]
        }
      ]
    }
  ]
}